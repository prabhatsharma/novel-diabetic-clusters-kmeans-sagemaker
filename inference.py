
import boto3
import numpy as np
import json
import joblib

client = boto3.client('sagemaker-runtime')

mean =  np.array([498.907, 50.0303, 29.4696, 2.289492000000002, 74.49937000000021])
std =  np.array([289.87433115711855, 28.657887384818498, 11.498821597442676, 1.306044393246921, 526.7579254124425])

inference_data = [758,64,36,2.83,50.28]

scaler = joblib.load('./local/scaler.gz') # This file will be generated by preprocessing job and will be in sagemaker s3 default bucket.

data = np.array(inference_data)
print(data)

data = data.reshape(1,5) # scaler requires 2D array
data = scaler.transform(data)
data = data.reshape(5,) # let's get our 1D array back

data = ",".join(map(str, data)) # convert to csv format

print(data)

response = client.invoke_endpoint(
    EndpointName='kmeans-2020-05-16-03-23-14-106',
    Body = data,
    ContentType='text/csv',
)

result = json.loads(response['Body'].read().decode())

print(result)



