{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker import KMeans\n",
    "import pandas as pd\n",
    "import io\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set basic config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.session.Session().region_name\n",
    "role = get_execution_role()\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "BUCKET = 'prabhat-ml' # replace with your bucket name\n",
    "KEY = 'diabetes/blog_synthetic/data/diabetes_data.csv' # replace with your object key\n",
    "\n",
    "input_data = 's3://' + BUCKET + '/' + KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=role,\n",
    "                                     instance_type='ml.m5.xlarge',\n",
    "                                     instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-scikit-learn-2020-05-25-21-16-53-909\n",
      "Inputs:  [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://prabhat-ml/diabetes/blog_synthetic/data/diabetes_data.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-2-107995894928/sagemaker-scikit-learn-2020-05-25-21-16-53-909/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train_data', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-2-107995894928/sagemaker-scikit-learn-2020-05-25-21-16-53-909/output/train_data', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'scaler', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-2-107995894928/sagemaker-scikit-learn-2020-05-25-21-16-53-909/output/scaler', 'LocalPath': '/opt/ml/processing/scaler', 'S3UploadMode': 'EndOfJob'}}]\n",
      "..................\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\u001b[0m\n",
      "\u001b[34mSaving scaler to:  /opt/ml/processing/scaler/scaler.gz\u001b[0m\n",
      "\u001b[34m---Transforming data---\u001b[0m\n",
      "\u001b[34m---Transforming complete ----\u001b[0m\n",
      "\u001b[34mSaving transformed training data to /opt/ml/processing/train/diabetes_data_transformed.csv\u001b[0m\n",
      "CPU times: user 404 ms, sys: 24.1 ms, total: 428 ms\n",
      "Wall time: 3min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "sklearn_processor.run(code='./preprocessing.py',\n",
    "                      inputs=[ProcessingInput(\n",
    "                        source=input_data,\n",
    "                        destination='/opt/ml/processing/input')],\n",
    "                      outputs=[ProcessingOutput(output_name='train_data',\n",
    "                                                source='/opt/ml/processing/train'),\n",
    "                               ProcessingOutput(output_name='scaler',\n",
    "                                                source='/opt/ml/processing/scaler')], # We will also use this to transform inference data\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()\n",
    "\n",
    "output_config = preprocessing_job_description['ProcessingOutputConfig']\n",
    "for output in output_config['Outputs']:\n",
    "    if output['OutputName'] == 'train_data':\n",
    "        preprocessed_training_data = output['S3Output']['S3Uri']\n",
    "    if output['OutputName'] == 'scaler':\n",
    "        preprocessed_scaler_data = output['S3Output']['S3Uri']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get preprocessed (transformed) training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-2-107995894928/sagemaker-scikit-learn-2020-05-25-21-16-53-909/output/train_data\n",
      "s3://sagemaker-us-east-2-107995894928/sagemaker-scikit-learn-2020-05-25-21-16-53-909/output/scaler\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed_training_data)\n",
    "print(preprocessed_scaler_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the bucket name and get the Key name from the transformed data\n",
    "BUCKET = preprocessed_training_data[5:preprocessed_training_data.find('/',5)]\n",
    "KEY = preprocessed_training_data[len(BUCKET)+6:len(preprocessed_training_data)]+ '/diabetes_data_transformed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = s3.get_object(Bucket=BUCKET, Key=KEY)\n",
    "response_body = response[\"Body\"].read()\n",
    "df = pd.read_csv(io.BytesIO(response_body), header=None, delimiter=\",\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure the Sagemaker KMeans estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_location = 's3://prabhat-ml/diabetes/blog_synthetic/output'    # place to store the generated model\n",
    "\n",
    "kmeans = KMeans(role=role,\n",
    "                train_instance_count=1,\n",
    "                train_instance_type='ml.c5.2xlarge',\n",
    "                output_path=output_location,\n",
    "                k=5\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-25 21:24:48 Starting - Starting the training job...\n",
      "2020-05-25 21:24:50 Starting - Launching requested ML instances......\n",
      "2020-05-25 21:25:55 Starting - Preparing the instances for training......\n",
      "2020-05-25 21:27:11 Downloading - Downloading input data\n",
      "2020-05-25 21:27:11 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'5', u'k': u'5', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'5', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'5', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 WARNING 140341438072640] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] Create Store: local\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] nvidia-smi took: 0.0251710414886 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'5', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'5', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5000, \"sum\": 5000.0, \"min\": 5000}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1590442046.310887, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1590442046.310849}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-25 21:27:26.311] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 21, \"num_examples\": 1, \"num_bytes\": 220000}\u001b[0m\n",
      "\u001b[34m[2020-05-25 21:27:26.376] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 64, \"num_examples\": 2, \"num_bytes\": 440000}\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] processed a total of 10000 examples\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 10000, \"sum\": 10000.0, \"min\": 10000}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}, \"Total Records Seen\": {\"count\": 1, \"max\": 15000, \"sum\": 15000.0, \"min\": 15000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 10000, \"sum\": 10000.0, \"min\": 10000}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1590442046.376682, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1590442046.311163}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] #throughput_metric: host=algo-1, train throughput=152376.63437 records/second\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 WARNING 140341438072640] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] shrinking 50 centers into 5\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] local kmeans attempt #0. Current mean square distance 0.121501\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] local kmeans attempt #1. Current mean square distance 0.128073\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] local kmeans attempt #2. Current mean square distance 0.120576\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] local kmeans attempt #3. Current mean square distance 0.120661\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] local kmeans attempt #4. Current mean square distance 0.123387\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] local kmeans attempt #5. Current mean square distance 0.120490\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] local kmeans attempt #6. Current mean square distance 0.128270\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] local kmeans attempt #7. Current mean square distance 0.130237\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] local kmeans attempt #8. Current mean square distance 0.121101\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] local kmeans attempt #9. Current mean square distance 0.128090\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] finished shrinking process. Mean Square Distance = 0\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] #quality_metric: host=algo-1, train msd <loss>=0.120489783585\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] compute all data-center distances: inner product took: 53.0023%, (0.037584 secs)\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] collect from kv store took: 9.3131%, (0.006604 secs)\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] splitting centers key-value pair took: 9.0438%, (0.006413 secs)\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] batch data loading with context took: 8.7035%, (0.006172 secs)\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] gradient: cluster center took: 5.6775%, (0.004026 secs)\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] predict compute msd took: 4.6046%, (0.003265 secs)\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] compute all data-center distances: point norm took: 3.1646%, (0.002244 secs)\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] gradient: one_hot took: 2.6444%, (0.001875 secs)\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] gradient: cluster size  took: 1.9501%, (0.001383 secs)\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] update state and report convergance took: 1.2074%, (0.000856 secs)\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] compute all data-center distances: center norm took: 0.3345%, (0.000237 secs)\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] update set-up time took: 0.2807%, (0.000199 secs)\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] predict minus dist took: 0.0733%, (0.000052 secs)\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] TOTAL took: 0.0709102153778\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 125.90622901916504, \"sum\": 125.90622901916504, \"min\": 125.90622901916504}, \"initialize.time\": {\"count\": 1, \"max\": 15.477180480957031, \"sum\": 15.477180480957031, \"min\": 15.477180480957031}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.1361370086669922, \"sum\": 0.1361370086669922, \"min\": 0.1361370086669922}, \"update.time\": {\"count\": 1, \"max\": 65.37604331970215, \"sum\": 65.37604331970215, \"min\": 65.37604331970215}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.7688999176025391, \"sum\": 0.7688999176025391, \"min\": 0.7688999176025391}, \"_shrink.time\": {\"count\": 1, \"max\": 124.64308738708496, \"sum\": 124.64308738708496, \"min\": 124.64308738708496}}, \"EndTime\": 1590442046.503876, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1590442046.288471}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/25/2020 21:27:26 INFO 140341438072640] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 275.88415145874023, \"sum\": 275.88415145874023, \"min\": 275.88415145874023}, \"setuptime\": {\"count\": 1, \"max\": 11.713981628417969, \"sum\": 11.713981628417969, \"min\": 11.713981628417969}}, \"EndTime\": 1590442046.504157, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1590442046.503963}\n",
      "\u001b[0m\n",
      "\n",
      "2020-05-25 21:27:36 Uploading - Uploading generated training model\n",
      "2020-05-25 21:27:36 Completed - Training job completed\n",
      "Training seconds: 44\n",
      "Billable seconds: 44\n",
      "CPU times: user 486 ms, sys: 33.8 ms, total: 520 ms\n",
      "Wall time: 3min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_data = df.to_numpy()\n",
    "train_data = np.float32(train_data) # alogorithm expects float32\n",
    "kmeans.fit(kmeans.record_set(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the model - create an inference endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!CPU times: user 248 ms, sys: 9.98 ms, total: 258 ms\n",
      "Wall time: 7min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kmeans_predictor = kmeans.deploy(initial_instance_count=1, \n",
    "                                 instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate sample inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = [291, 97, 41, 9, 0.82, 22.56]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download scaler for transforming the inference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the bucket name and get the Key name from the transformed data\n",
    "BUCKET = preprocessed_scaler_data[5:preprocessed_training_data.find('/',5)]\n",
    "KEY = preprocessed_scaler_data[len(BUCKET)+6:len(preprocessed_scaler_data)]+ '/scaler.gz'\n",
    "\n",
    "s3.download_file(BUCKET, KEY, 'scaler.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "scaler = joblib.load(\"scaler.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform inference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data = np.array(test_sample).reshape(1,6)\n",
    "t_data = np.reshape(t_data, (1,-1))\n",
    "t_data = scaler.transform(t_data)\n",
    "t_data = np.float32(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.758517  , 0.64285713, 0.6666667 , 0.44288224, 0.0026005 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = kmeans_predictor.predict(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[label {\n",
       "   key: \"closest_cluster\"\n",
       "   value {\n",
       "     float32_tensor {\n",
       "       values: 0.0\n",
       "     }\n",
       "   }\n",
       " }\n",
       " label {\n",
       "   key: \"distance_to_cluster\"\n",
       "   value {\n",
       "     float32_tensor {\n",
       "       values: 0.15986494719982147\n",
       "     }\n",
       "   }\n",
       " }]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}